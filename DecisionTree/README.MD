# Decision Tree

实现了决策树的一种ID3算法，并使用matplotlib把决策树画出来。

## ID3

该算法是以信息增益为准则，进行属性划分的。这样会对取值比较多的属性的选择有所偏好，C4.5就对该策略进行了改进--先从候选划分属性中找出信息增益高于平均水平的属性，在从中选择增益率最高的属性。而CART使用Gini index来选择划分属性，课用于分类和回归。

实现了ID3，对uci lenses数据集进行构建决策树，并使用matplotlib画出来决策树。

## NOTICE

* 过拟合问题

  * 预剪枝(prepruning)，降低过拟合，减少训练时间，但是会带来欠拟合风险。
  * 后剪枝(postpruning)，会比预剪枝保留更多分治，欠拟合风险小，但是训练时间大。

* 连续值处理问题

  二分法(bi-partition)，将某连续值属性出现的值从大到小排序，考虑n-1个划分点进行二分。若当前节点划分属性为连续属性，该属性可作为其后代节点的划分属性。

* 缺失值处理问题

  * 1， 如何进行划分属性的选择？ 按照各自比例，修改信息增益计算公式。
  * 2， 对于给定的属性，若有缺失值如何进行样本划分？ 若样本x在划分属性a上取值已知，则归入对应子节点，样本权值为w_x。若取值未知，则将x同时划入所有子节点，将每个子节点下的样本x权值调整为w_x*该属性值样本所占比例。